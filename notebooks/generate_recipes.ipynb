{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating recipies with character-level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Get the data from here http://www.ffts.com/recipes/lg/lg32965.zip and unzip it into data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/1000.mmf'),\n",
       " PosixPath('data/18000.mmf'),\n",
       " PosixPath('data/14000.mmf'),\n",
       " PosixPath('data/22000.mmf'),\n",
       " PosixPath('data/30000.mmf')]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"data\")\n",
    "files = [f for f in PATH.iterdir() if str(f).endswith('.mmf')]\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMM----- Recipe via Meal-Master (tm) v8.05\r",
      "\r\n",
      " \r",
      "\r\n",
      "      Title: \"BE MINE\" LOLLIPOPS\r",
      "\r\n",
      " Categories: Candies, Valentine\r",
      "\r\n",
      "      Yield: 8 Servings\r",
      "\r\n",
      " \r",
      "\r\n",
      "           Text only\r",
      "\r\n",
      " \r",
      "\r\n",
      "  Source: Better Homes and Gardens, Febuary 1998 Prep time: 20 minutes\r",
      "\r\n",
      "  Cook: 6 to 8 minutes\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head data/1000.mmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "def read_file(path):\n",
    "    with open(path, encoding=\"utf8\", errors='ignore') as f:\n",
    "        content = unidecode.unidecode(f.read())\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = read_file(\"data/1000.mmf\")\n",
    "content2 = read_file(\"data/18000.mmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330591"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n + n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330591"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = content2 + content\n",
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMMMM----- Recipe via Meal-Master (tm) v8.05\\n \\n      Title: \"BE MINE\" LOLLIPOPS\\n Categories: Candies, Valentine\\n      Yield: 8 Servings\\n \\n           Text only\\n \\n  Source: Better Homes and Gardens, Febuary 1998 Prep time: 20 minutes\\n  Cook: 6 to 8 minutes\\n  \\n  2 1/2 to 3 1/2-inch round or heart-shaped metal cookie cutters 8 oz.\\n  assorted red, pink, and/or clearhard candies 35 to 60 (2 to 3 oz.)\\n  assorted small decorative candies, such as red cinnamon candies,\\n  small nonpareils, colored candy hearts, spice drops, and gumdrops\\n  Edible rose petals or other flower petals (optional) Lollipop sticks\\n  \\n  Place unwrapped hard candies in a heavy plastic bag, then place bag\\n  on top of folded towel and crush candies into small chunks wiht meat\\n  mallet or small hammer.\\n  \\n  Make only three or four lollipops at one time.  Line a baking sheet\\n  with foil.  Place desired cookie cutters on foil, at least 2 inches\\n  apart. Divide crushed candies evenly among cutters, approximately 1\\n  1/2 to 2 ta'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226806"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "all_characters = string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters = len(all_characters)\n",
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14,\n",
       "       94, 31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28, 29, 14, 27, 94,\n",
       "       69, 29, 22, 70, 94, 31,  8, 75,  0,  5, 96, 94, 96, 94, 94, 94, 94,\n",
       "       94, 94, 55, 18, 29, 21, 14, 77, 94, 63, 37, 40, 94, 48, 44, 49, 40,\n",
       "       63, 94, 47, 50, 47, 47, 44, 51, 50, 51, 54, 96, 94, 38, 10, 29, 14,\n",
       "       16, 24, 27, 18, 14, 28, 77, 94, 38, 10, 23, 13, 18, 14, 28])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy way to encode characters\n",
    "np.array([all_characters.index(c) for c in content[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=1000\n",
    "contents = [content[i*seq_len:(i+1)*seq_len] for i in range(n//seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)*seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters.index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_encoding(c):\n",
    "    if c in all_characters:\n",
    "        return all_characters.index(c)\n",
    "    else:\n",
    "        return all_characters.index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do one file \n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, files, seq_len=1000):\n",
    "        content_list = [read_file(path) for path in files]\n",
    "        all_content = '\\n'.join(content_list) \n",
    "        n = len(all_content)\n",
    "        self.contents = [all_content[i*seq_len:(i+1)*seq_len] for i in range(n//seq_len)]\n",
    "        # shift by 1\n",
    "        self.ys = [all_content[i*seq_len + 1 :(i+1)*seq_len +1] for i in range(n//seq_len)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.contents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.contents[idx]\n",
    "        y = self.ys[idx]\n",
    "        x = np.array([char_encoding(c) for c in x])\n",
    "        y = np.array([char_encoding(c) for c in y])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RecipeDataset(files, seq_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([48, 48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14,\n",
       "        94, 31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28]),\n",
       " array([48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14, 94,\n",
       "        31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28, 29]))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can start by just sending one file\n",
    "train_ds = RecipeDataset(files, seq_len=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, vocab_size):\n",
    "        super(RecipeRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.linear_i2h = nn.Linear(emb_size + hidden_size, hidden_size)\n",
    "        self.linear_h2o = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.emb(x)\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = torch.tanh(self.linear_i2h(combined))\n",
    "        output = self.linear_h2o(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, bash_size):\n",
    "        return torch.zeros(bash_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(vocab_size, emb_size)\n",
    "linear_i2h = nn.Linear(emb_size + hidden_size, hidden_size)\n",
    "linear_h2o = nn.Linear(hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 10000]), torch.Size([100, 10000]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.initHidden(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "for i in range(x.shape[1]):\n",
    "    y_t, h = model(x[:,i].long(), h)\n",
    "    loss += F.cross_entropy(y_t, y[:, i].long())\n",
    "loss /= x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.600766658782959"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that just the last x_t is used in the loss\n",
    "# update\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.00001):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y in train_dl:\n",
    "        batch = x.shape[0]\n",
    "        h = model.initHidden(batch)\n",
    "        loss = 0\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        for i in range(x.shape[1]):\n",
    "            out, h = model(x[:,i], h)\n",
    "            loss += F.cross_entropy(out, y[:, i])\n",
    "        loss /= x.shape[1]\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, lr, train_dl, epochs=20):\n",
    "    optim = get_optimizer(model, lr =lr, wd = 0.0)\n",
    "    for i in range(epochs):\n",
    "        loss = train(model, optim, train_dl)\n",
    "        if i%5 == 1: print(\"train loss %.3f\" % (loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.790\n",
      "train loss 1.297\n",
      "train loss 1.219\n",
      "train loss 1.184\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 0.01, train_dl,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.165\n",
      "train loss 1.154\n",
      "train loss 1.148\n",
      "train loss 1.143\n",
      "train loss 1.139\n",
      "train loss 1.135\n",
      "train loss 1.132\n",
      "train loss 1.133\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 0.005, train_dl, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating recipies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.initHidden(1)\n",
    "inp = torch.LongTensor([all_characters.index(\"M\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([1, 150]))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emb(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = model(inp, hidden)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0613e+00, 2.1690e-01, 2.2201e+00, 6.1470e+00, 1.9417e+01, 8.9415e+00,\n",
       "        5.8167e+00, 3.8950e+00, 4.2628e+00, 4.6476e+01, 2.9842e+03, 1.2852e-03,\n",
       "        1.3073e-07, 8.4796e-01, 1.1086e+01, 1.0129e-07, 7.6991e-07, 2.0800e-06,\n",
       "        1.2902e+01, 2.5205e-01, 6.3959e+00, 1.7370e+01, 1.7380e-02, 3.1636e-03,\n",
       "        7.1844e-01, 5.2591e-02, 6.2821e-08, 9.9094e-01, 3.0495e-03, 4.4327e-07,\n",
       "        3.4999e+00, 3.3331e-05, 5.4827e-01, 2.4415e-07, 1.8985e+01, 2.9808e-04,\n",
       "        1.6576e+04, 2.4528e+02, 1.6555e+02, 8.7970e+00, 1.7682e+04, 6.1712e+00,\n",
       "        4.7572e-01, 3.8814e+03, 1.3298e+03, 1.7504e+01, 5.7753e+02, 9.5614e+01,\n",
       "        8.5813e+06, 5.6439e+00, 1.5649e+03, 2.1953e+04, 3.5365e-01, 2.2424e+02,\n",
       "        1.1302e+02, 6.3186e+00, 2.2203e+02, 6.2968e-01, 5.2581e+01, 3.8127e+00,\n",
       "        9.9553e+01, 1.9314e+01, 8.1497e+00, 9.7066e-03, 5.4864e-01, 9.7470e-03,\n",
       "        3.8440e-02, 2.1784e-01, 7.5550e+00, 1.2557e-03, 1.4396e+00, 5.7630e-01,\n",
       "        5.3449e-02, 2.0615e+00, 1.9625e+01, 3.8333e+00, 4.8938e+00, 7.4914e+01,\n",
       "        1.5674e+00, 1.2801e-01, 1.4834e+02, 3.6068e+00, 2.9746e-01, 4.4662e+01,\n",
       "        8.2238e-01, 5.6492e-01, 1.7150e+00, 1.0983e-01, 1.1594e+02, 4.9134e-02,\n",
       "        5.0024e-01, 4.9611e+01, 1.5698e+00, 7.5560e-04, 1.1546e+01, 1.6217e-02,\n",
       "        3.7382e+01, 8.3142e-02, 1.9183e+00, 2.5303e-01])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature=0.8\n",
    "output_dist = output.data.view(-1).div(temperature).exp()\n",
    "output_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_i = torch.multinomial(output_dist, 1)\n",
    "top_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_char = all_characters[top_i]\n",
    "predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, predict_len=1000, temperature=0.8, start_char=\"M\"):\n",
    "    hidden = model.initHidden(1)\n",
    "    inp = torch.LongTensor([all_characters.index(start_char)])\n",
    "    predicted = start_char\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i[0]]\n",
    "        predicted += predicted_char\n",
    "        inp = top_i\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWICHA CHICKENGO SAUCE----------------------------------\n",
      "    1/2 c  May)\n",
      "           Yoilt, in pepper. Refrigerate and salt; all over slices is the batter into a warm)\n",
      "      1    Garlic container in casserole, and\n",
      "  water or the chicken of bulb of a\n",
      "  beans\n",
      "           - about 3 inches of eggs.\n",
      "  \n",
      "  Set Pecoomstillosed in 1-2 la rouctry\n",
      "  medium heat, pepper and pasta OF Eggs\n",
      "           -(blenders in kseads\n",
      "           -eggs and chilled and bake all lightly gravla, milk.\n",
      "  \n",
      "                                                                                                                                                                                   \n",
      "  Recipe By     :\n",
      "  \n",
      "  Ground pall or chicken by keep pan brown sugar\n",
      "    1/4 c  Fresh\n",
      "           -- the twice, pour in sugarves of tomato over medium-high hour. Bring to taste.   In a should brown, and cool and cook peppers\n",
      "           -(g chicken parts.  Turn of wheat sauce over low heat in the mustard, the conserten Ched margarine, milk and \n"
     ]
    }
   ],
   "source": [
    "predicted = generate(model, predict_len=1000, temperature=0.8, start_char=\"D\")\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMCOLLIGATE CAKE\n",
      " Categories: Meats, December or for the bar (3) desired format egg and simmer 2 minutes oa the in the powder\n",
      "      1 ts Butter, sliced\n",
      "      1 c  Straw\n",
      "      1 c  Water\n",
      "      1    Lemon chopped\n",
      "           Chopped\n",
      "      1 tb Salt\n",
      "  cover container wine of heat, peppers, Indiesy. Time on the\n",
      "  spices\n",
      "      1 c  Fine\n",
      "      1 c  Milk\n",
      "    3/4 c  Sugar\n",
      "    1/2 c  Floruce cheese, minced\n",
      "      1 ts Salt\n",
      "        2 quse 1 brots to the to dough in egg bowl, way beas mixture in water in the dough is frying\n",
      "  serving seeds, Sauces to think\n",
      "      1    Egg\n",
      "      2 tb Hoy tablespoon and remaining whipped almond cheese the mago=; Mix to eashrone; garlic\n",
      "  or one quarted toie vegetables, cool balls are skillet cheese\n",
      "      2 tb Soy suttie and peel ground and stepping until with the boil. Heat the eggs each.  Makes of a can necessary sauce, turnuts & 4 sarbogeter soak\n",
      "           - juice, heaviamin\n",
      "           - \"Demoni be unbagreming that that the\n",
      "  lemon juice\n",
      "    1/4 c  Butter\n",
      "      1 \n"
     ]
    }
   ],
   "source": [
    "predicted = generate(model, predict_len=1000, temperature=0.8)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMM.7ASSER TRED ON THE SALAD\n",
      " Categories: Chili peeles into desired punt out granulaned holiday\n",
      "  from this corn it dish. Rollet. **TOma. [Cook and tossive out the boiling water incorpos of day almond extract\n",
      "  1 1/2 ts Sodium-Mast,\n",
      "        wittom and baking sheets with microwaves\n",
      "    1/4 c  Crushed and about 2 minutes. Serve.  Saute. Bake over mucksent almond combined Vinegar\n",
      "      1 ts Peel\n",
      "           Seasone letts a pasta\n",
      "      2 c  An the pan. Mix to boiler and seal onions and spices, green notes\n",
      "  cookies brown,\n",
      "  skin. Top will pans\n",
      "           Garlic sue befots per gring mixture.\n",
      "  \n",
      "  Cook and garlic, Indian center hands of the ingredients in for the 17 dboped\n",
      "  or raw adding.\n",
      "  \n",
      "  Diced and pan and casted ex3, or until ozzlers are sanda sliced sauce in more the paste very spread beef beef some the cheese and almond extract\n",
      "        2    Egg Nancepted and chopped hot soy.  Mix the dough of a cookie sheet of the remaining conbeding your shake blumbles\n",
      "      3 tb Chili\n",
      "      Yield:\n"
     ]
    }
   ],
   "source": [
    "predicted = generate(model, predict_len=1000, temperature=0.8)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "The generator is modified from this https://github.com/spro/char-rnn.pytorch/blob/282bcb6b15ab3929d6a588b455cfc0f19f32add4/generate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
